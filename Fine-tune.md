HyperNetwork

Adapter

Additive Learning circumvents forgetting by freezing the
original model weights and adding a small number of new parameters using learned weight masks [51 , 74 ], pruning [52],
or hard attention [80 ]. Side-Tuning [92 ] uses a side branch
model to learn extra functionality by linearly blending the
outputs of a frozen model and an added network, with a
predefined blending weight schedule.

Low-Rank Adaptation: learning the offset of parameters with low-rank matrices.